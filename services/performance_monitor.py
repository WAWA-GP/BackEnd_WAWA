# services/performance_monitor.py

import time
import json
from datetime import datetime
import asyncio
from functools import wraps
from collections import defaultdict
import numpy as np
import os

class PerformanceMonitor:
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤.
    """
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(PerformanceMonitor, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        if hasattr(self, 'initialized'):
            return
        self.records = defaultdict(list)
        self.initialized = True
        print("âœ… Performance Monitorê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def record_execution_time(self, feature_name: str, duration_ms: float):
        """ê¸°ëŠ¥ë³„ ì‹¤í–‰ ì‹œê°„ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
        self.records[feature_name].append(duration_ms)

    def _calculate_statistics(self):
        """ê¸°ë¡ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        stats = {}
        for feature, durations in self.records.items():
            if not durations:
                continue

            stats[feature] = {
                "avg_execution_time_ms": np.mean(durations),
                "min_execution_time_ms": np.min(durations),
                "max_execution_time_ms": np.max(durations),
                "call_count": len(durations),
                "total_execution_time_ms": np.sum(durations)
            }
        return stats

    def generate_report(self):
        """ìµœì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ JSON íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.records:
            print("ğŸ“ ê¸°ë¡ëœ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        stats = self._calculate_statistics()
        report = {
            "test_metadata": {
                "test_name": "Live Backend Non-AI Performance Report",
                "generated_at": datetime.now().isoformat()
            },
            "overall_summary": {
                "total_functions_measured": len(stats),
                "total_calls_recorded": sum(f['call_count'] for f in stats.values())
            },
            "function_performance_results": {}
        }

        benchmarks = {
            "Database I/O Bound": {"excellent": 200, "good": 400, "fair": 800, "poor": 1000},
            "CPU Bound": {"excellent": 1, "good": 5, "fair": 10, "poor": 20}
        }

        feature_types = {
            "íšŒì›ê°€ì…": "Database I/O Bound", "ë¡œê·¸ì¸": "Database I/O Bound",
            "í”„ë¡œí•„ ì¡°íšŒ": "Database I/O Bound", "í•™ìŠµ ê³„íš ìƒì„±": "Database I/O Bound",
            "í†µê³„ ê³„ì‚°": "CPU Bound"
        }

        for feature, data in stats.items():
            feature_type = feature_types.get(feature, "Database I/O Bound")
            benchmark = benchmarks[feature_type]
            avg_time = data['avg_execution_time_ms']

            status = "ê°œì„ í•„ìš”"
            if avg_time <= benchmark['excellent']: status = "ìš°ìˆ˜"
            elif avg_time <= benchmark['good']: status = "ì–‘í˜¸"
            elif avg_time <= benchmark['fair']: status = "ë³´í†µ"

            report["function_performance_results"][feature] = {
                "status": status,
                "avg_execution_time_ms": round(avg_time, 2),
                "min_execution_time_ms": round(data['min_execution_time_ms'], 2),
                "max_execution_time_ms": round(data['max_execution_time_ms'], 2),
                "call_count": data['call_count'],
                "type": feature_type,
                "benchmark_ms": benchmark
            }

        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"live_performance_report_{timestamp}.json"

        # reports ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists('reports'):
            os.makedirs('reports')

        filepath = os.path.join('reports', filename)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"âœ… ì„±ëŠ¥ ë¦¬í¬íŠ¸ê°€ '{filepath}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ë°ì½”ë ˆì´í„° ìƒì„± ---
performance_monitor = PerformanceMonitor()

def measure_performance(feature_name: str):
    """í•¨ìˆ˜ì˜ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê³  ê¸°ë¡í•˜ëŠ” ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤."""
    def decorator(func):
        # ë¹„ë™ê¸° í•¨ìˆ˜ì™€ ë™ê¸° í•¨ìˆ˜ë¥¼ ëª¨ë‘ ì§€ì›
        if asyncio.iscoroutinefunction(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                start_time = time.perf_counter()
                result = await func(*args, **kwargs)
                end_time = time.perf_counter()
                duration_ms = (end_time - start_time) * 1000
                performance_monitor.record_execution_time(feature_name, duration_ms)
                return result
            return async_wrapper
        else:
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                start_time = time.perf_counter()
                result = func(*args, **kwargs)
                end_time = time.perf_counter()
                duration_ms = (end_time - start_time) * 1000
                performance_monitor.record_execution_time(feature_name, duration_ms)
                return result
            return sync_wrapper
    return decorator
